{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.transforms as TF\n",
    "from cl_lite.head.dynamic_simple import DynamicSimpleHead\n",
    "import cl_lite.backbone as B\n",
    "import os\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from rdfcil.datamodule import DataModule\n",
    "\n",
    "dataset = \"imagenet100\"\n",
    "num_classes = 100\n",
    "data_root = '../rdfcil/data'\n",
    "class_order = [68, 56, 78, 8, 23, 84, 90, 65, 74, 76, 40, 89, 3, 92, 55, 9, 26, 80, 43, 38, 58, 70, 77, 1, 85, 19, 17, 50, 28, 53, 13, 81, 45, 82, 6, 59, 83, 16, 15, 44, 91, 41, 72, 60, 79, 52, 20, 10, 31, 54, 37, 95, 14, 71, 96, 98, 97, 2, 64, 66, 42, 22, 35, 86, 24, 34, 87, 21, 99, 0, 88, 27, 18, 94, 11, 12, 47, 25, 30, 46, 62, 69, 36, 61, 7, 63, 75, 5, 32, 4, 51, 48, 73, 93, 39, 67, 29, 49, 57, 33]\n",
    "num_tasks = 20\n",
    "\n",
    "# Convert class_order to a tensor for faster indexing\n",
    "class_order_tensor = torch.tensor(class_order).cuda()\n",
    "\n",
    "# Create a tensor of zeros with the same length as class_order\n",
    "# This tensor will be used to create a mapping where the index is the class order position\n",
    "mapping_tensor = torch.zeros(len(class_order), dtype=torch.long).cuda()\n",
    "\n",
    "# Assign the new class indices (which are just the indices of class_order_tensor) to the corresponding positions in mapping_tensor\n",
    "mapping_tensor[class_order_tensor] = torch.arange(len(class_order_tensor)).cuda()\n",
    "\n",
    "# Use the mapping tensor to map the labels\n",
    "# fast_mapped_labels = mapping_tensor[labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 1\n",
      " idx: 2\n",
      "[0.83]\n",
      "Task 2\n",
      " idx: 4\n",
      "[0.644, 0.79]\n",
      "Task 3\n",
      " idx: 6\n",
      "[0.548, 0.652, 0.71]\n",
      "Task 4\n",
      " idx: 8\n",
      "[0.328, 0.492, 0.708, 0.73]\n",
      "Task 5\n",
      " idx: 10\n",
      "[0.368, 0.232, 0.676, 0.42, 0.74]\n",
      "Task 6\n",
      " idx: 12\n",
      "[0.292, 0.328, 0.484, 0.38, 0.56, 0.775]\n",
      "Task 7\n",
      " idx: 14\n",
      "[0.276, 0.296, 0.56, 0.292, 0.384, 0.576, 0.635]\n",
      "Task 8\n",
      " idx: 16\n",
      "[0.32, 0.276, 0.264, 0.252, 0.348, 0.304, 0.588, 0.745]\n",
      "Task 9\n",
      " idx: 18\n",
      "[0.284, 0.184, 0.38, 0.244, 0.364, 0.348, 0.552, 0.496, 0.645]\n",
      "Task 10\n",
      " idx: 20\n",
      "[0.332, 0.18, 0.328, 0.232, 0.32, 0.224, 0.44, 0.296, 0.484, 0.6]\n",
      "Task 11\n",
      " idx: 22\n",
      "[0.172, 0.136, 0.268, 0.204, 0.296, 0.224, 0.376, 0.284, 0.416, 0.504, 0.795]\n",
      "Task 12\n",
      " idx: 24\n",
      "[0.22, 0.188, 0.2, 0.2, 0.292, 0.24, 0.332, 0.276, 0.428, 0.256, 0.548, 0.64]\n",
      "Task 13\n",
      " idx: 26\n",
      "[0.2, 0.188, 0.156, 0.144, 0.312, 0.14, 0.18, 0.172, 0.364, 0.228, 0.54, 0.584, 0.79]\n",
      "Task 14\n",
      " idx: 28\n",
      "[0.172, 0.156, 0.2, 0.16, 0.288, 0.212, 0.188, 0.256, 0.344, 0.204, 0.4, 0.484, 0.488, 0.735]\n",
      "Task 15\n",
      " idx: 30\n",
      "[0.168, 0.076, 0.124, 0.132, 0.26, 0.204, 0.272, 0.26, 0.336, 0.22, 0.416, 0.524, 0.476, 0.532, 0.645]\n",
      "Task 16\n",
      " idx: 32\n",
      "[0.212, 0.156, 0.18, 0.12, 0.244, 0.112, 0.22, 0.18, 0.36, 0.18, 0.408, 0.444, 0.36, 0.532, 0.452, 0.58]\n",
      "Task 17\n",
      " idx: 34\n",
      "[0.124, 0.096, 0.092, 0.144, 0.272, 0.18, 0.212, 0.208, 0.308, 0.204, 0.428, 0.376, 0.344, 0.396, 0.416, 0.448, 0.59]\n",
      "Task 18\n",
      " idx: 36\n",
      "[0.116, 0.136, 0.136, 0.104, 0.276, 0.172, 0.224, 0.22, 0.308, 0.16, 0.356, 0.352, 0.376, 0.388, 0.384, 0.344, 0.452, 0.36]\n",
      "Task 19\n"
     ]
    }
   ],
   "source": [
    "# get forgetting results\n",
    "total_task_acc=[]\n",
    "for t in range(1,num_tasks+1):\n",
    "    print(f\"Task {t}\")\n",
    "    \n",
    "    # get the model\n",
    "    if dataset.startswith(\"imagenet\"):\n",
    "        backbone = B.resnet.resnet18()\n",
    "    else:\n",
    "        backbone = ISCF_ResNet()\n",
    "\n",
    "    # prefix = './ImageNet-100/imnet100_version_675_rdfcil_5task_49.44/task_{}'.format(t-1)\n",
    "    # prefix = './ImageNet-100/version_508_imnet_5task_54.64/task_{}'.format(t-1)\n",
    "    # prefix = './ImageNet-100/version_507_imnet_20task_32.90/task_{}/'.format(t-1)\n",
    "    prefix = './ImageNet-100/version_793_imnet_20t_rdfcil/task_{}/'.format(t-1)\n",
    "    # prefix = './ImageNet-100/version_451_imnet_10task_45.18/task_{}/'.format(t-1)\n",
    "    # prefix = './ImageNet-100/imnet100_version_430_rdfcil_10task_40.7/task_{}/'.format(t-1)\n",
    "    state_dict = torch.load(os.path.join(prefix,\"checkpoints/best_acc.ckpt\"))['state_dict']\n",
    "\n",
    "    # dataload\n",
    "    data_module = DataModule(root=data_root, \n",
    "                            dataset=dataset, \n",
    "                            batch_size=128, \n",
    "                            num_workers=4,\n",
    "                            num_tasks=num_tasks,\n",
    "                            class_order=class_order,\n",
    "                            current_task=t-1,\n",
    "                            )\n",
    "    data_module.setup()\n",
    "    head = DynamicSimpleHead(num_classes=data_module.num_classes, num_features=backbone.num_features, bias=False)\n",
    "    # head = DynamicSimpleHead(num_classes=data_module.num_classes, num_features=backbone.num_features, bias=True)\n",
    "    \n",
    "    backbone_state= {}\n",
    "    head_state = {}\n",
    "    for _ in range(t-1):\n",
    "        head.append(num_classes//num_tasks)\n",
    "    for k,v in state_dict.items():\n",
    "        if k.startswith('backbone'):\n",
    "            backbone_state[k[9:]] = v\n",
    "        elif k.startswith('head'):\n",
    "            head_state[k[5:]] = v\n",
    "            # head_state[k[17:]] = v\n",
    "            \n",
    "        \n",
    "    backbone.load_state_dict(backbone_state)\n",
    "    backbone.eval()\n",
    "    head.load_state_dict(head_state)\n",
    "\n",
    "\n",
    "    # train_dataloader = data_module.train_dataloader()\n",
    "    val_dataloader = data_module.val_dataloader()\n",
    "\n",
    "    backbone.cuda()\n",
    "    head.cuda()\n",
    "\n",
    "    task_correct= [0 for _ in range(t)]\n",
    "    task_total = [0 for _ in range(t)]\n",
    "    idx=0\n",
    "    for batch in val_dataloader:\n",
    "        images, labels = batch\n",
    "        images = images.cuda()\n",
    "        labels = labels.cuda()\n",
    "        with torch.no_grad():\n",
    "            output = backbone(images)\n",
    "            output = head(output)\n",
    "            # print(output[0],labels[0])\n",
    "            labels = mapping_tensor[labels]\n",
    "            for i in range(t):\n",
    "                t_indices = torch.nonzero(torch.bitwise_and(num_classes//num_tasks*(i+1) >= labels, num_classes//num_tasks*(i) < labels) ).view(-1)\n",
    "                # print(t_indices.view(-1))\n",
    "                # task accuracy\n",
    "                labels_t = labels[t_indices] # - i*num_classes//num_tasks\n",
    "                output_t = output[t_indices]\n",
    "                # if i==0:\n",
    "                #     output_t = output_t[:,:num_classes//num_tasks*(i+1)]\n",
    "                # else: output_t = output_t[:,num_classes//num_tasks*i:num_classes//num_tasks*(i+1)]\n",
    "                task_correct[i] += (output_t.argmax(dim=1) == labels_t).sum().item()\n",
    "                task_total[i] += len(labels_t)\n",
    "        idx+=1\n",
    "        print('\\r idx: {}'.format(idx), end='')\n",
    "    print()\n",
    "    task_acc = [float(cc)/ct for cc,ct in zip(task_correct,task_total)]\n",
    "    print(task_acc)\n",
    "\n",
    "    for j in range(num_tasks-t):\n",
    "        task_acc.append(0)\n",
    "    total_task_acc.append(task_acc)\n",
    "total_task_acc = np.array(total_task_acc)\n",
    "print(total_task_acc)\n",
    "result = []\n",
    "for i in range(num_tasks):\n",
    "    if i == 0:\n",
    "        result.append(0)\n",
    "    else:\n",
    "        res = 0\n",
    "        for j in range(i + 1):\n",
    "            res += (np.max(total_task_acc[:, j]) - total_task_acc[i][j])\n",
    "        res = res / i\n",
    "        result.append(100 * res)\n",
    "\n",
    "        \n",
    "print('Forgetting result:')\n",
    "print(result)\n",
    "print(sum(result)/len(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "forgetting = np.max(total_task_acc,axis=0) - np.min(total_task_acc,axis=0)\n",
    "print(forgetting)\n",
    "avg_forgetting = np.mean(forgetting)\n",
    "print(avg_forgetting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
